{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490cb53b-3eb4-49ff-b101-241ee7de7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import norm\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"TkAgg\")\n",
    "import ddpm\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17772673-bcac-4079-95cd-a2ae435e7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = range(100, 5000, 400)\n",
    "sizes = [2500]\n",
    "names = [f\"point_2d{s}\" for s in sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a886df7-a87f-46a4-a911-c5bcf40cd783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "sMIN GAMMA tensor(4.3165e-06, dtype=torch.float64) LEN 50\n",
      "Training model 0...\n",
      "END LOSS WAS 1.0378519071325878\n",
      "Saving model...\n",
      "Training model 1...\n",
      "END LOSS WAS 0.8919519670135705\n",
      "Saving model...\n",
      "Training model 2...\n",
      "END LOSS WAS 0.9048583430954108\n",
      "Saving model...\n",
      "Training model 3...\n",
      "END LOSS WAS 0.9335633894609214\n",
      "Saving model...\n",
      "Training model 4...\n",
      "END LOSS WAS 0.7973158165292966\n",
      "Saving model...\n",
      "Training model 5...\n",
      "END LOSS WAS 0.7869084193318385\n",
      "Saving model...\n",
      "Training model 6...\n",
      "END LOSS WAS 0.827351789152277\n",
      "Saving model...\n",
      "Training model 7...\n",
      "END LOSS WAS 0.03150011332932531\n",
      "Saving model...\n",
      "Training model 8...\n",
      "END LOSS WAS 0.01953048085248614\n",
      "Saving model...\n",
      "Training model 9...\n",
      "END LOSS WAS 0.00736420549120336\n",
      "Saving model...\n",
      "Training model 10...\n",
      "END LOSS WAS 0.00913519150172068\n",
      "Saving model...\n",
      "Training model 11...\n",
      "END LOSS WAS 0.004931943196921421\n",
      "Saving model...\n",
      "Training model 12...\n",
      "END LOSS WAS 0.0013446011370140468\n",
      "Saving model...\n",
      "Training model 13...\n",
      "END LOSS WAS 8.941738122758094e-05\n",
      "Saving model...\n",
      "Training model 14...\n",
      "END LOSS WAS 2.8541284800806794e-06\n",
      "Saving model...\n",
      "Training model 15...\n",
      "END LOSS WAS 0.002839345442249495\n",
      "Saving model...\n",
      "Training model 16...\n",
      "END LOSS WAS 8.567018194622804e-07\n",
      "Saving model...\n",
      "Training model 17...\n",
      "END LOSS WAS 4.834223470619491e-06\n",
      "Saving model...\n",
      "Training model 18...\n",
      "END LOSS WAS 0.0005817871682259545\n",
      "Saving model...\n",
      "Training model 19...\n",
      "END LOSS WAS 0.00012246319260235432\n",
      "Saving model...\n",
      "Training model 20...\n",
      "END LOSS WAS 4.523557860702362e-05\n",
      "Saving model...\n",
      "Training model 21...\n",
      "END LOSS WAS 7.072673732874866e-05\n",
      "Saving model...\n",
      "Training model 22...\n",
      "END LOSS WAS 0.0014751388776263908\n",
      "Saving model...\n",
      "Training model 23...\n",
      "END LOSS WAS 0.00013628998408463783\n",
      "Saving model...\n",
      "Training model 24...\n",
      "END LOSS WAS 0.0003680309850752378\n",
      "Saving model...\n",
      "Training model 25...\n",
      "END LOSS WAS 0.0004474413037143251\n",
      "Saving model...\n",
      "Training model 26...\n",
      "END LOSS WAS 0.005918804927790815\n",
      "Saving model...\n",
      "Training model 27...\n",
      "END LOSS WAS 6.909345656328807e-05\n",
      "Saving model...\n",
      "Training model 28...\n",
      "END LOSS WAS 0.00014825192782585593\n",
      "Saving model...\n",
      "Training model 29...\n",
      "END LOSS WAS 0.0006442967907537176\n",
      "Saving model...\n",
      "Training model 30...\n",
      "END LOSS WAS 0.00014909512094704412\n",
      "Saving model...\n",
      "Training model 31...\n",
      "END LOSS WAS 0.0001558506677737073\n",
      "Saving model...\n",
      "Training model 32...\n",
      "END LOSS WAS 0.00047876588810587544\n",
      "Saving model...\n",
      "Training model 33...\n",
      "END LOSS WAS 0.001212047390327464\n",
      "Saving model...\n",
      "Training model 34...\n",
      "END LOSS WAS 0.0001572758324607437\n",
      "Saving model...\n",
      "Training model 35...\n",
      "END LOSS WAS 0.001120151170148199\n",
      "Saving model...\n",
      "Training model 36...\n",
      "END LOSS WAS 0.0010980908073430172\n",
      "Saving model...\n",
      "Training model 37...\n",
      "END LOSS WAS 0.0011994158036551321\n",
      "Saving model...\n",
      "Training model 38...\n",
      "END LOSS WAS 0.0006306386976920716\n",
      "Saving model...\n",
      "Training model 39...\n",
      "END LOSS WAS 0.008339845017118205\n",
      "Saving model...\n",
      "Training model 40...\n",
      "END LOSS WAS 0.00020708089674773442\n",
      "Saving model...\n",
      "Training model 41...\n",
      "END LOSS WAS 0.0008934809930619665\n",
      "Saving model...\n",
      "Training model 42...\n",
      "END LOSS WAS 0.00011016015767887017\n",
      "Saving model...\n",
      "Training model 43...\n",
      "END LOSS WAS 0.00020241445060048072\n",
      "Saving model...\n",
      "Training model 44...\n",
      "END LOSS WAS 0.0028159756641615375\n",
      "Saving model...\n",
      "Training model 45...\n",
      "END LOSS WAS 0.00015662781497342474\n",
      "Saving model...\n",
      "Training model 46...\n",
      "END LOSS WAS 0.0006161829669723036\n",
      "Saving model...\n",
      "Training model 47...\n",
      "END LOSS WAS 0.0003006303307315401\n",
      "Saving model...\n",
      "Training model 48...\n",
      "END LOSS WAS 0.00016289537962633423\n",
      "Saving model...\n",
      "Training model 49...\n",
      "END LOSS WAS 0.0006121517526145477\n",
      "Saving model...\n",
      "Saving loss as numpy array...\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sizes)):\n",
    "    print(sizes[i])\n",
    "    !python ddpm.py --dataset circle --experiment_name {names[i]} --num_epochs 50 --dataset_size {sizes[i]} --beta_schedule ours --num_timesteps 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "074d1abf-9bd3-4f20-90f5-804fe97345a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(model_dir, dataset='point', score='model'):\n",
    "    num_scheduler_timesteps = 1000\n",
    "    noise_scheduler = ddpm.NoiseScheduler(num_timesteps=num_scheduler_timesteps, beta_schedule='ours')\n",
    "    num_timesteps = len(noise_scheduler)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    models = [ddpm.MLP(input_dim=2) for _ in range(num_timesteps)]\n",
    "    for t in range(num_timesteps):\n",
    "        path = model_dir + f\"/model{t}.pth\"\n",
    "        models[t].load_state_dict(torch.load(path))\n",
    "        models[t].to(device)\n",
    "        models[t].eval()\n",
    "    eval_batch_size = 100000\n",
    "    plot_step = 1\n",
    "    num_timesteps = len(noise_scheduler.betas)\n",
    "    curr_vars = torch.sqrt(1 - torch.exp(-2 * noise_scheduler.times))\n",
    "    sample = torch.randn(eval_batch_size, 2).to(device).to(device)\n",
    "    timesteps = list(range(num_timesteps))[::-1][:-5]\n",
    "    print(\"LAST STD\", curr_vars[timesteps[-1]].item())\n",
    "    samples = []\n",
    "    steps = []\n",
    "    for i, t in enumerate(tqdm(timesteps)):\n",
    "        t_int = t\n",
    "        t = torch.from_numpy(np.repeat(t, eval_batch_size)).long().to(device)\n",
    "        with torch.no_grad():\n",
    "            variance = torch.sqrt(1 - noise_scheduler.alphas_cumprod[t])\n",
    "            v = curr_vars[t].cpu().numpy()\n",
    "            if score == 'model':\n",
    "                residual = models[t_int](sample, t)\n",
    "            else:\n",
    "                residual = sample / variance.unsqueeze(-1)\n",
    "        sample = noise_scheduler.step(residual, t[0], sample)\n",
    "        if (i + 1) % plot_step == 0:\n",
    "            sample_cpu = sample.cpu()\n",
    "            samples.append(sample_cpu.numpy())\n",
    "            steps.append(i + 1)\n",
    "    if dataset == 'ret':\n",
    "        return samples\n",
    "    elif dataset == 'square':\n",
    "        return process_square(samples[-1], mode='median')\n",
    "    elif dataset == 'point2d':\n",
    "        return process_point2d(samples[-1], mode='median')\n",
    "    elif dataset == 'circle':\n",
    "        return process_circle(samples[-1], r=3, mode='median')\n",
    "    elif dataset == 'point':\n",
    "        return process_point(samples[-1], mode='median')\n",
    "    else:\n",
    "        raise ValueError(\"INVALID DATASET\")\n",
    "def process_square(samples, r=3, mode='median'):\n",
    "    t = 0\n",
    "    d = []\n",
    "    for s in samples:\n",
    "        dists = [abs(s[0] - r), abs(s[0] + r), abs(s[1] - r), abs(s[1] + r)]\n",
    "        m = min(dists)\n",
    "        d.append(m)\n",
    "    # d = sorted(d)[:-round(len(d)*0.02)]\n",
    "    if mode == 'median':\n",
    "        return sorted(d)[len(d)//2]\n",
    "    for m in d:\n",
    "        t += m**2\n",
    "    t /= len(d)\n",
    "    return np.sqrt(t)\n",
    "def process_point2d(samples, mode='median'):\n",
    "    norms = np.apply_along_axis(np.linalg.norm, 1, samples)\n",
    "    print(\"MEAN\", np.mean(norms), \"MEDIAN\", np.median(norms))\n",
    "    return np.median(norms)\n",
    "    # med = np.median(norms)\n",
    "def process_point(samples, mode='median'):\n",
    "    return np.median(samples)\n",
    "    centered = samples.squeeze() - np.mean(samples.squeeze())\n",
    "    print(np.mean(samples.squeeze()))\n",
    "    return np.median(centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a92977cc-20b5-4679-ac33-c41820621ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 point_2d2500\n",
      "sMIN GAMMA tensor(4.3165e-06, dtype=torch.float64) LEN 50\n",
      "LAST STD 4.220806844430688e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba344f85935b4ef0ab4da6f49e6eda49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN 0.0020550592167652673 MEDIAN 6.0824007237356736e-05\n"
     ]
    }
   ],
   "source": [
    "s = []\n",
    "for i in range(len(sizes)):\n",
    "    print(sizes[i], names[i])\n",
    "    s.append(np.abs(calculate_stats(f\"exps/{names[i]}\", dataset='point2d', score='model')))\n",
    "plt.clf()\n",
    "plt.scatter(sizes, np.array(s))\n",
    "plt.yscale('log')\n",
    "plt.title(\"median error vs dataset size\")\n",
    "plt.ylabel(\"median error\")\n",
    "plt.xlabel(\"dataset size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75e16b72-2e44-4b58-95f7-85afb5955ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = [1 / x for x in s]\n",
    "plt.clf()\n",
    "plt.scatter(sizes, np.array(s2))\n",
    "# plt.yscale('log')\n",
    "plt.title(\"median error vs dataset size\")\n",
    "plt.ylabel(\"median error\")\n",
    "plt.xlabel(\"dataset size\")\n",
    "plt.savefig(f'static/devs_point2d.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c9aec51-0182-40f6-af6a-518dbed64a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sMIN GAMMA tensor(4.3165e-06, dtype=torch.float64) LEN 50\n"
     ]
    }
   ],
   "source": [
    "model_dir = f\"exps/{names[-1]}\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "noise_scheduler = ddpm.NoiseScheduler(num_timesteps=1000, beta_schedule='ours')\n",
    "num_timesteps = len(noise_scheduler.times)\n",
    "models = [ddpm.MLP(input_dim=2) for _ in range(num_timesteps)]\n",
    "for t in range(num_timesteps):\n",
    "    path = model_dir + f\"/model{t}.pth\"\n",
    "    models[t].load_state_dict(torch.load(path))\n",
    "    models[t].to(device)\n",
    "    models[t].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19966cfd-1f5a-4ae6-9e6d-e980a6a3e013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.3165e-06, 7.7347e-06, 1.2284e-05, 1.8768e-05, 2.8238e-05, 4.2208e-05,\n",
      "        6.2907e-05, 9.3635e-05, 1.3929e-04, 2.0716e-04, 3.0805e-04, 4.5806e-04,\n",
      "        6.8110e-04, 1.0127e-03, 1.5058e-03, 2.2390e-03, 3.3291e-03, 4.9500e-03,\n",
      "        7.3599e-03, 1.0943e-02, 1.6269e-02, 2.4184e-02, 3.5938e-02, 5.3369e-02,\n",
      "        7.9136e-02, 1.1696e-01, 1.7168e-01, 2.4849e-01, 3.5035e-01, 4.7334e-01,\n",
      "        6.0371e-01, 7.2296e-01, 8.1800e-01, 8.8584e-01, 9.3060e-01, 9.5865e-01,\n",
      "        9.7566e-01, 9.8578e-01, 9.9173e-01, 9.9520e-01, 9.9722e-01, 9.9839e-01,\n",
      "        9.9907e-01, 9.9946e-01, 9.9969e-01, 9.9982e-01, 9.9990e-01, 9.9994e-01,\n",
      "        9.9997e-01, 9.9998e-01], device='cuda:0', dtype=torch.float64)\n",
      "0.0003080510901544058\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x_scale, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m times \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(inputs))\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;241m*\u001b[39m t\n\u001b[0;32m---> 10\u001b[0m model_residuals \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m true_residuals \u001b[38;5;241m=\u001b[39m inputs \u001b[38;5;241m/\u001b[39m v\n",
      "File \u001b[0;32m/work/00935/adityaup/miniconda3/envs/scores/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/00935/adityaup/miniconda3/envs/scores/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/00935/adityaup/ls6/tiny-diffusion/ddpm.py:50\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     49\u001b[0m     x1_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_mlp1(x[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 50\u001b[0m     x2_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_mlp2(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     51\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x1_emb, x2_emb), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     52\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoint_mlp(x)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "curr_stds = torch.sqrt(1 - torch.exp(-2 * noise_scheduler.times))\n",
    "print(curr_stds)\n",
    "t = 10\n",
    "v = curr_stds[t].item()\n",
    "print(v)\n",
    "x_scale = np.linspace(-v * 5, v * 5, 1000)\n",
    "# x_scale = np.linspace(-10, 10, 1000)\n",
    "inputs = torch.tensor(x_scale, device=device).unsqueeze(1)\n",
    "times = torch.ones(len(inputs)).to(device) * t\n",
    "model_residuals = models[t](inputs, times)\n",
    "true_residuals = inputs / v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9084b4e-6f81-478c-ab30-8c05d17438c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_scale, model_residuals.data.cpu().numpy(), label='model')\n",
    "plt.plot(x_scale, true_residuals.data.cpu().numpy(), label='true')\n",
    "for y in (np.arange(11)-5)*v:\n",
    "    plt.axvline(y, alpha=1 if y == 0 else 0.2)\n",
    "plt.legend()\n",
    "plt.savefig(\"score.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d07e3bc9-fe05-44ba-9378-a636c48ed259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'curr_vars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(t)\n\u001b[0;32m----> 4\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[43mcurr_vars\u001b[49m[t]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      5\u001b[0m     x_range \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39mv\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m, v\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      6\u001b[0m     diff \u001b[38;5;241m=\u001b[39m x_range[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m x_range[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'curr_vars' is not defined"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for t in range(50):\n",
    "    print(t)\n",
    "    v = curr_vars[t].cpu().numpy()\n",
    "    x_range = np.linspace(-v*5, v*5, 1000)\n",
    "    diff = x_range[1] - x_range[0]\n",
    "    l2 = 0\n",
    "    difc = 0\n",
    "    pc = 0\n",
    "    tot = 0\n",
    "    for i in x_range:\n",
    "        v = curr_vars[t]\n",
    "        pdf = norm.pdf(i, 0, v.item())\n",
    "        model_val = model(torch.tensor([[i]], device=device, dtype=torch.float32), torch.ones(1, device=device, dtype=torch.float32)*t)\n",
    "        true_val = torch.tensor([[i]], device=device) / torch.sqrt(1 - torch.exp(-2 * noise_scheduler.times[t]))\n",
    "        error = (model_val.data.cpu().numpy() - true_val.data.cpu().numpy())[0]\n",
    "        l2 += (error**2)*diff*pdf\n",
    "        difc += diff\n",
    "        pc += pdf\n",
    "        tot += diff*pdf\n",
    "    print(l2, difc, tot, v.item()*2)\n",
    "    errors.append(l2*v.item()*v.item())\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bc504836-98f0-4510-9905-3ee2d4bcc2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6831737563750486\n"
     ]
    }
   ],
   "source": [
    "x_range = np.linspace(-10, 10, 1000)\n",
    "diff = x_range[1] - x_range[0]\n",
    "tot = 0\n",
    "for i in x_range:\n",
    "    tot += diff * norm.pdf(i, 0, 10)\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c7a860e-5ded-47d4-9f24-af54828102c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point_2d4900\n",
      "sMIN GAMMA tensor(4.3165e-06, dtype=torch.float64) LEN 50\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "t = 5\n",
    "slice_index = 1\n",
    "print(names[-1])\n",
    "model_path = f\"exps/{names[-1]}/model{t}.pth\"\n",
    "model = ddpm.MLP(input_dim=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "noise_scheduler = ddpm.NoiseScheduler(num_timesteps=1000, beta_schedule=\"ours\")\n",
    "curr_vars = torch.sqrt(1 - torch.exp(-2 * noise_scheduler.times))\n",
    "v = curr_vars[t].item()\n",
    "scores = []\n",
    "x_scale = torch.linspace(-v * 5, v * 5, 1000)\n",
    "if slice_index == 0:\n",
    "    inputs = torch.stack((x_scale, torch.zeros(1000)), dim=1).to(device)\n",
    "else:\n",
    "    inputs = torch.stack((torch.zeros(1000), x_scale), dim=1).to(device)\n",
    "print(noise_scheduler.betas.shape)\n",
    "times = torch.ones(len(inputs), device=device)*t\n",
    "model_residuals = model(inputs, times)\n",
    "true_residuals = inputs / v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e386d0a5-633e-414a-acf1-2af22ece2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(x_scale, model_residuals.data.cpu().numpy()[:, slice_index], label='model')\n",
    "plt.plot(x_scale, true_residuals.data.cpu().numpy()[:, slice_index], label='true')\n",
    "for y in (np.arange(11)-5)*v:\n",
    "    plt.axvline(y, alpha=1 if y == 0 else 0.2)\n",
    "plt.legend()\n",
    "plt.savefig(\"score.png\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba2f9649-e01b-461c-afe9-6acb49580e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.123105625617661"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 4], [1, 1], [3, 4]])\n",
    "np.median(np.apply_along_axis(np.linalg.norm, 1, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2acc0-ae32-4b5c-9277-e1f68153b900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
